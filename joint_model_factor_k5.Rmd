---
title: "Joint model -- factor model covariance (5 factors)"
author: "Glenn Palmer"
date: "2024-12-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rstan)
library(shinystan)
library(scales)
library(viridis)
library(ggcorrplot)
library(multcomp)
library(lubridate)
library(chron)
library(edfReader)
library(xtable)
library(stats)
library(infinitefactor)
library(coda)
library(sns)
```

## R Markdown

This notebook imports the APPLES data (stored on my local computer here, so change the file paths as needed to re-run elsewhere), fits the model from the paper with k=5 factors, and then generates some model summaries and figures.


```{r}
# import harmonized data
covariate_df <- read_csv("/Users/glennpalmer/Desktop/sleep_research_2024/apples/datasets/apples-harmonized-dataset-0.1.0.csv")

# just keep the rows describing the PSG visit
covariate_df <- covariate_df |>
  filter(!is.na(fileid))

# import baseline characteristics
baseline_df <- read_csv("/Users/glennpalmer/Desktop/sleep_research_2024/apples/original/CSV Exports from APPLES Investigator Database/APPLES Baseline Characteristics.csv")

# merge the datasets, keeping only the subjects in the covariate data
covariate_df <- covariate_df |>
  left_join(baseline_df, by=c(nsrrid="APPLEID"))
```


```{r}
##### helper functions for importing/cleaning data

# check that transitions are lined up in two vectors
check_alignment <- function(svec) {
  transition_align <- which(svec[2:length(svec)] - svec[1:(length(svec)-1)] != 0)[1] %% 30
  return(transition_align)
}

# add digits to beginning of vector to make the transitions line up
check_and_prepend_alignment <- function(svec) {
  a <- check_alignment(svec)
  if (a != 29) {
    new_svec <- c(rep(svec[1], (29-a)), svec)
    print(paste0("Adding ", (29-a), " indices to beginning of stage_vec for alignment."))
    return(new_svec)
  }
  return(svec)
}

# try to align stages and epoch pairs to those noted in event_vec
align_epoch_stage_pairs <- function(svec, evec, svec_event, evec_event, addlimit=20) {
  addcount <- 0
  for (i in 1:(length(evec_event)-70)) {
    if (svec[30*evec_event[i] - 29] != svec_event[i]) {
      svec <- c(rep(11,29), svec[1], svec)
      addcount <- addcount + 1
    }
    if (addcount > addlimit) {
      print(paste0("Added more than ", addlimit,  " epochs -- check alignment manually."))
      return(svec)
    }
  }
  print(paste0("Successfully added ", addcount, " epochs to start of stage vector."))
  return(svec)
}

# check that all stages and epochs are aligned
check_epoch_stage_pairs <- function(svec, evec, svec_event, evec_event) {
  # note -- leaving out the final handful of epochs to avoid weird issues
  for (i in 1:(length(evec_event)-70)) {
    #print(paste0("Checking event epoch ", i, "."))
    if (svec[30*evec_event[i] - 29] != svec_event[i]) {
      print("Epochs and stages are misaligned")
      return(1)
    }
  }
  return(0)
}

```


```{r}
# function to import a single patient's data
get_single_patient_transitions <- function(id_number) {
  ########### get stage_df and epoch_vec set up correctly ##########
  
  # set patient_num
  patient_num <- id_number
  
  # import stage_df
  stage_df <- read_csv(paste0("/Users/glennpalmer/Desktop/sleep_research_2024/apples/original/PSG Exports/apples-", patient_num, "STAGE.csv"))
  names(stage_df) <- c("stage")
  stage_df <- stage_df |>
    dplyr::select(stage)
  
  # import events df
  event_df <- read_csv(paste0("/Users/glennpalmer/Desktop/sleep_research_2024/apples/original/PSG Exports/apples-", patient_num, ".csv"))
  names(event_df)<-str_replace_all(names(event_df), c(" " = "." , "," = "" ))
  
  # exclude outages from event_df
  event_df <- event_df |>
    dplyr::filter(Event.type != "'tech out\",W\"")
  
  # Convert sleep stages in event_df to have same format as stage_df
  event_df <- event_df |>
    dplyr::mutate(stageval = case_when(
      Stage == "W" ~ 11,
      Stage == "R" ~ 12,
      Stage == "N1" ~ 13,
      Stage == "N2" ~ 14,
      Stage == "N3" ~ 15
    ))
  
  # create epoch counter vector -- first epoch 29 seconds
  epoch_vec <- c(rep(1,29), rep(2:1500, each=30))
  
  # pull out stage_vec from stage_df
  stage_vec <- stage_df$stage
  
  # check that the transitions in sleep stages and epochs are lined up
  stage_vec <- check_and_prepend_alignment(stage_vec)
  
  # loop over event stage/epoch pairs and make sure they're aligned
  eventstage_vec <- as.numeric(event_df$stageval)
  eventepoch_vec <- as.numeric(event_df$Epoch)
  check_align <- check_epoch_stage_pairs(stage_vec, epoch_vec, eventstage_vec, eventepoch_vec)
  if (check_align != 0) {
    stage_vec <- 
      align_epoch_stage_pairs(stage_vec, epoch_vec, eventstage_vec, eventepoch_vec)
  } 
  check_align <- check_epoch_stage_pairs(stage_vec, epoch_vec, eventstage_vec, eventepoch_vec)
  if (check_align == 0) {
    print("Epoch and stage alignment successful!")
  }
  if (check_align != 0) {
    print(paste0("Epoch and stage alignment failed for patient ", patient_num, "."))
    return(1)
  }
  
  
  # Add values to end of a few patients requiring it
  if (patient_num %in% c(250145, 440032, 450071, 450098)) {
    stage_vec <- c(stage_df$stage, 14)
    stage_df <- data.frame(stage_vec)
    names(stage_df) <- c("stage")
  }
  if (patient_num %in% c(440048)) {
    stage_vec <- c(stage_df$stage, 13)
    stage_df <- data.frame(stage_vec)
    names(stage_df) <- c("stage")
  }  
  
  
  
  #### Get apnea events aligned and added
  
  # filter event_df for apnea events
  event_df <- event_df |>
    filter(Event.type == "Hypopnea" | Event.type == "Obstructive apnea" | Event.type == "Central apnea" | Event.type == "Mixed apnea")
  
  # Some patients have times using AM/PM -- convert as needed
  if (patient_num == 240094) {
    for (i in 1:nrow(event_df)) {
      # super messy way to convert am/pm to military time string
      event_df$Time[i] <- substring(as.character(parse_date_time(event_df$Time[i],
                                                                 '%I:%M:%S %p')),
                                    nchar(as.character(parse_date_time(event_df$Time[i],
                                                                       '%I:%M:%S %p'))) - 8 + 1)
    }
    event_df$Time <- hms(event_df$Time)
  }
  
  # import start time from edf file
  starttime <- readEdfHeader(paste0("/Users/glennpalmer/Desktop/sleep_research_2024/apples/original/PSG Exports/apples-", patient_num, ".edf"))$startTime
  
  # put start_time in same format as other fake times
  starttime_vec <- c(NA, 1)
  if (hour(starttime) > 16) {
    starttime_vec[1] <- ISOdate(year=1, month=1, day=1,
                         hour=hour(starttime),
                         min=minute(starttime),
                         sec=second(starttime))
  }
  if (hour(starttime) <= 16) {
    starttime_vec[1] <- c(ISOdate(year=1, month=1, day=2,
                         hour=hour(starttime),
                         min=minute(starttime),
                         sec=second(starttime)))
  }
  starttime <- starttime_vec[1]
  
  # make event_time and event_faketime vectors and populate
  event_time <- event_df$Time
  event_faketime <- rep(NA, length(event_time))
  for (i in 1:length(event_time)) {
    if (hour(event_time[i]) > 16 & patient_num != 140095) {
      event_faketime[i] <- ISOdate(year=1, month=1, day=1,
                       hour=hour(event_time[i]),
                       min=minute(event_time[i]),
                       sec=second(event_time[i]))
    }
    else {
      event_faketime[i] <- ISOdate(year=1, month=1, day=2,
                       hour=hour(event_time[i]),
                       min=minute(event_time[i]),
                       sec=second(event_time[i]))
    }
  }
  
  # compute event index
  event_index <- event_faketime - starttime
  
  # check that events are placed in correct epochs
  eventepoch_vec <- event_df$Epoch
  for (i in 1:length(event_index)) {
    #print(paste0("Checking event ", i, "."))
    if (event_index[i] == 0) {
      if (eventepoch_vec[i] != 1) {
        print(paste0("Incorrect epoch for event ", i, "."))
        return(1)
      }
    }
    else if (epoch_vec[event_index[i]] != eventepoch_vec[i]) {
      print(paste0("Incorrect epoch for event ", i, "."))
      return(1)
    }
  }
  
  # get durations
  event_durations <- as.integer(ceiling(as.numeric(word(event_df$Duration, 1))))
  
  # create binary vector with indicator of event currently happening
  event_happening <- rep(0, length(stage_vec))
  for (i in 1:length(event_index)) {
    if (event_index[i] != 0) {
    event_happening[event_index[i]:(event_index[i] + event_durations[i] - 1)] <-
      rep(1,event_durations[i])
    }
    else {
      event_happening[event_index[i]:(event_index[i] + event_durations[i] - 1)] <-
      rep(1,(event_durations[i] - 1))
    }
  }
  # cut off final indices of event_happening if it goes beyond the length of stage_vec
  event_happening <- event_happening[1:length(stage_vec)]
  
  
  # create counter vector for cumulative number of events
  cum_event_vec <- rep(NA, length(stage_vec))
  curr_count <- 0
  for (i in 1:length(stage_vec)) {
    if (event_happening[i] == 1) {
      if (i == 1) {
        curr_count <- curr_count + 1
      }
      else if (event_happening[i-1] == 0) {
        curr_count <- curr_count + 1
      }
    }
    cum_event_vec[i] <- curr_count
  }
  
  # create updated stage_df
  stage_df <- data.frame(stage_vec, epoch_vec[1:length(stage_vec)], event_happening, cum_event_vec)
  names(stage_df) <- c("stage", "epoch", "event", "cum_events")  
  
  
  
  # proceed as usual
  
  # Collapse non-REM stages
  stage_df <- stage_df |>
    mutate(stage = case_when(
      stage == 11 ~ 11,
      stage == 12 ~ 12,
      stage >= 13 ~ 13
    ))
  
  # update stage_vec
  stage_vec <- stage_df$stage
  
  # At this point, stage_df provides enough to get the necessary info for modeling interevent times
  qR <- 0 # number of seconds spent in REM (excluding time during events except the second of onset)
  vR <- 0 # number of apnea/hypopnea events in REM
  qN <- 0 # number of seconds spend in non-REM sleep (excluding time during events except the second of onset)
  vN <- 0 # number of apnea/hypopnea events in non-REM sleep
  
  # loop over the dataframe and increment the above quantities
  for (i in 2:nrow(stage_df)) {
    if (stage_vec[i] == 12) {
      qR <- qR + 1
      if (event_happening[i] == 1 & event_happening[i-1] == 0) {
        vR <- vR + 1
      }
      else if (event_happening[i] == 1) {
        qR <- qR - 1
      }
    }
    else if (stage_vec[i] == 13) {
      qN <- qN + 1
      if (event_happening[i] == 1 & event_happening[i-1] == 0) {
        vN <- vN + 1
      }
      else if (event_happening[i] == 1) {
        qN <- qN - 1
      }
    }
  }
  
  qR
  vR
  qN
  vN
  
  # collapse stage_df to epoch-level
  stage_epoch_df <- stage_df |>
    group_by(epoch) |>
    #summarize(stage=mean(stage), event=(n_distinct(event) - 1))
    summarize(stage=mean(stage), event=(sum(event) > 0))
  
  # add a next-stage variable and a cumulative events variable
  stage_epoch_df$next_stage <- c(stage_epoch_df$stage[2:nrow(stage_epoch_df)], NA)
  
  # summarize counts of all combinations of stage, next_stage, and event -- EDITED FOR ONLY 3 STAGES
  stage_transition_counts <- data.frame(rep(12:13, each=6),
                                        rep(rep(11:13, each=2), 2),
                                        rep(c(0,1), 6))
  names(stage_transition_counts) <- c("stage", "next_stage", "event")
  
  # count observed transitions
  stage_transition_observed <- stage_epoch_df |>
    group_by(stage, next_stage, event) |>
    count() |>
    filter(!is.na(next_stage) & stage != 11)
  
  # merge counts with all combinations
  stage_transition_counts <- stage_transition_counts |>
    left_join(stage_transition_observed)
  
  # recode unobserved combinations as zero counts
  for (i in 1:nrow(stage_transition_counts)) {
    if (is.na(stage_transition_counts$n[i])) {
      stage_transition_counts$n[i] <- 0
    }
  }
  

  
  
  
  # create Y matrix for the current patient
  Y_event_curr <- c(qR,vR,qN,vN)
  
  Y_curr <- matrix(rep(NA, 12), ncol=3)
  Y_curr[1,] <- stage_transition_counts$n[c(1,3,5)]
  Y_curr[2,] <- stage_transition_counts$n[c(2,4,6)]
  Y_curr[3,] <- stage_transition_counts$n[c(7,9,11)]
  Y_curr[4,] <- stage_transition_counts$n[c(8,10,12)]
  
  # also return longest event
  longest_duration <- max(event_durations)
  
  # return data
  return(list(Y_curr, Y_event_curr, longest_duration))
}
```

```{r}
# check to make sure it's working
get_single_patient_transitions(140014)
```

```{r}
# loop over multiple patients to get Y, X, and Z
get_multiple_patient_data <- function(id_numbers) {
  N <- length(id_numbers)
  longest_event <- rep(NA, length(id_numbers))
  
  # import first patient
  print(paste0("Importing patient id ", id_numbers[1], "(Patient ", 1, ")"))
  Y <- get_single_patient_transitions(id_numbers[1])[[1]]
  Y_event <- get_single_patient_transitions(id_numbers[1])[[2]]
  longest_event[1] <- get_single_patient_transitions(id_numbers[1])[[3]]
  
  # loop over the rest of them
  for (i in 2:N) {
    print(paste0("Importing patient id ", id_numbers[i], "(Patient ", i, ")"))
    curr_data <- get_single_patient_transitions(id_numbers[i])
    Y <- rbind(Y, curr_data[[1]])
    Y_event <- rbind(Y_event, curr_data[[2]])
    longest_event[i] <- curr_data[[3]]
  }
  
  # make X matrix
  XZ_single <- t(matrix(c(1,0,0,0,
                     1,0,1,0,
                     0,1,0,0,
                     0,1,0,1), ncol=4))
  
  X <- kronecker(matrix(rep(1,N), nrow=N), XZ_single)
  Z <- kronecker(diag(N), XZ_single)
  
  # return the results
  return(list(Y, X, Z, Y_event, longest_event))
}
```



```{r}
# collect all patient ids
psg_list <- list.files("/Users/glennpalmer/Desktop/sleep_research_2024/apples/original/PSG Exports")
patient_ids <- c()
for (i in 1:length(psg_list)) {
  patient_ids <- c(patient_ids, as.numeric(substr(psg_list[i], 8, 13)))
}

# filter out duplicates
patient_ids <- unique(patient_ids)

# filter out patients with inconsistent sleep stage data
# (i.e., mismatched between the stage and apples-idnumber csv files)
bad_ids <- c(560210,
             560226)


# filter out ids with no REM sleep
no_rem_list <- c(140054,
                 170395,
                 250132,
                 250209,
                 260315,
                 270379,
                 340037,
                 460197,
                 550159)

patient_ids <- patient_ids[!(patient_ids %in% no_rem_list) & !(patient_ids %in% bad_ids)]

length(bad_ids)
length(no_rem_list)
length(patient_ids)
length(c(bad_ids, no_rem_list, patient_ids))
```

```{r message=FALSE}
# Import all patients
transition_data <- get_multiple_patient_data(patient_ids)

Y <- transition_data[[1]]
X <- transition_data[[2]]
Z <- transition_data[[3]]
Y_event <- transition_data[[4]]
longest_events <- transition_data[[5]]
N <- length(patient_ids)
```


```{r}
# note patient(s) who have zero seconds in either REM or non-REM sleep
patient_ids[which(Y_event[,1]==0)]
which(Y_event[,3]==0)
```

```{r}
# Shuffling Y to have the reference level always be the current stage
Y_selfreference <- matrix(data=rep(NA, 4*N*3), nrow=4*N)
for (i in 1:N) {
  Y_selfreference[4*(i-1) + 1,] <- Y[4*(i-1) + 1, c(2,1,3)]
  Y_selfreference[4*(i-1) + 2,] <- Y[4*(i-1) + 2, c(2,1,3)]
  Y_selfreference[4*(i-1) + 3,] <- Y[4*(i-1) + 3, c(3,1,2)]
  Y_selfreference[4*(i-1) + 4,] <- Y[4*(i-1) + 4, c(3,1,2)]
}
```

```{r}
# fit the full model in stan

# load model
joint_model_factor <-
  stan_model("joint_fit_factormodel.stan")

# fit model
num_patients <- length(patient_ids)
N <- length(patient_ids)
k <- 5 # five factors
options(mc.cores = parallel::detectCores())
joint_fit_factor <- sampling(joint_model_factor,
                       list(N=N,
                            k=k,
                            Y=Y_selfreference,
                            X=X,
                            Z=Z,
                            Y_seconds=Y_event[,c(1,3)],
                            Y_eventcounts=Y_event[,c(2,4)]),
                       iter=5000)

# save model
saveRDS(joint_fit_factor, "joint_fit_factor_k5_n1093_m2500_chain4.rds")
```


```{r}
# extract posterior samples and visualize
post_samples_event <- extract(joint_fit_factor)
```


```{r}
# ESS and Rhat -- main effects

# lambda_N
effectiveSize(mcmc(data=matrix(post_samples_event$lambda_N, ncol=1)))
Rhat(matrix(post_samples_event$lambda_N, ncol=4))

# lambda_R
effectiveSize(mcmc(data=matrix(post_samples_event$lambda_R, ncol=1)))
Rhat(matrix(post_samples_event$lambda_R, ncol=4))

# mus and taus
for (i in 1:4) {
  for (j in 1:2) {
    print(effectiveSize(mcmc(data=matrix(post_samples_event$mu_tau[,i,j], ncol=1))))
    print(Rhat(matrix(post_samples_event$mu_tau[,i,j], ncol=4)))
  }
}
```

```{r}
# ESS and Rhat -- random effects

# minimum ess and maximum rhat for random effects
min_ess <- 10000
max_rhat <- 1

# phi_N and phi_R
for (i in 1:1093) {
  ess_phi_N <- effectiveSize(mcmc(matrix(data=post_samples_event$phi_N[,i], ncol=1)))
  ess_phi_R <- effectiveSize(mcmc(matrix(data=post_samples_event$phi_R[,i], ncol=1)))
  rhat_phi_N <- Rhat(matrix(data=post_samples_event$phi_N[,i], ncol=4))
  rhat_phi_R <- Rhat(matrix(data=post_samples_event$phi_R[,i], ncol=4))
  
  if (ess_phi_N < min_ess) {
    min_ess <- ess_phi_N
  }
  if (ess_phi_R < min_ess) {
    min_ess <- ess_phi_R
  }
  if (rhat_phi_N > max_rhat) {
    max_rhat <- rhat_phi_N
  }
  if (rhat_phi_R > max_rhat) {
    max_rhat <- rhat_phi_R
  }
}

# alphas and gammas
for (i in 1:4372) {
  for (j in 1:2) {
    curr_ess <- effectiveSize(mcmc(matrix(data=post_samples_event$gamma_alpha[,i,j], ncol=1)))
    curr_rhat <- Rhat(matrix(data=post_samples_event$gamma_alpha[,i,j], ncol=4))
    if (curr_ess < min_ess) {
      min_ess <- curr_ess
    }
    if (curr_rhat > max_rhat) {
      max_rhat <- curr_rhat
    }
  }
}

# print out the min ess and max rhat for the random effects
min_ess
max_rhat
```

```{r}
# ESS and Rhat -- RE covariance matrix
min_ess_cov <- 10000
max_rhat_cov <- 1

# make array for covariance matrix
cov_mat_array <- array(dim=c(10000,10,10))
for (i in 1:10000) {
  cov_mat_array[i,,] <- post_samples_event$Lambda[i,,] %*% t(post_samples_event$Lambda[i,,]) +
    diag(post_samples_event$Sigma[i,])
}

# loop over covariance matrix
for (i in 1:10) {
  for (j in 1:i) {
    curr_ess <- effectiveSize(mcmc(matrix(cov_mat_array[,i,j], ncol=1)))
    curr_rhat <- Rhat(matrix(cov_mat_array[,i,j],ncol=1))
    if (curr_ess < min_ess_cov) {
      min_ess_cov <- curr_ess
    }
    if (curr_rhat > max_rhat_cov) {
      max_rhat_cov <- curr_rhat
    }
  }
}

# min ess and max rhat for the random effect covariance matrix
min_ess_cov
max_rhat_cov
```


Overall takeaway -- all ESS above 2700 and all Rhat below 1.02 for all main effects, random effects, and random effect covariance terms.


# Posterior summaries

```{r}
# plot some posterior trace plots
plot(post_samples_event$mu_tau[,1,1], type="l")

plot(post_samples_event$phi_R[,1], type="l")

plot(post_samples_event$Sigma[,1], type="l")

plot(post_samples_event$lambda_N, type="l")

plot(post_samples_event$lambda_R, type="l")

plot(post_samples_event$gamma_alpha[,2,2], type="l")
```


```{r}
# visualize covariance and correlation matrices
post_samples_event$Lambda[1,,] %*% t(post_samples_event$Lambda[1,,])
diag(post_samples_event$Sigma[1,])

# posterior mean of RE covariance matrix
cov_mat <- matrix(data=rep(0,100), nrow=10, ncol=10)
for (i in 1:10000) {
  cov_mat <- cov_mat + post_samples_event$Lambda[i,,] %*% t(post_samples_event$Lambda[i,,]) + diag(post_samples_event$Sigma[i,])
}
cov_mat <- cov_mat / 10000
cov_mat

corr_mat <- cov2cor(cov_mat)
corr_mat
```

```{r}
# add names to correlation matrix for plotting
colnames(corr_mat) <- c("gamma_RA",
                       "gamma_NA",
                       "alpha_RA",
                       "alpha_NA",
                       "gamma_RN",
                       "gamma_NR",
                       "alpha_RN",
                       "alpha_NR",
                       "phi_R",
                       "phi_N")
rownames(corr_mat) <- colnames(corr_mat)
corr_mat

# reorder the columns and rows for plotting
corr_mat <- corr_mat[c(1,3,5,7,6,8,2,4,9,10), c(1,3,5,7,6,8,2,4,9,10)]
corr_mat
```

```{r}
# plot the correlation matrix -- SELF: should white out any where the 95% CI includes zero
ggcorrplot(corr_mat,
           colors = c("blue", "white", "darkorange2"))
```

```{r}
# form array of covariance samples
cov_mat_samples <- array(dim=c(10,10,10000))
for (i in 1:10000) {
  cov_mat_samples[,,i] <- post_samples_event$Lambda[i,,] %*% t(post_samples_event$Lambda[i,,]) + diag(post_samples_event$Sigma[i,])
}


# mixing of covariance matrix
for (i in 1:10) {
  for (j in 1:i) {
    plot(cov_mat_samples[i,j,], type="l", main=paste0("Cov_",i,j))
  }
}
```


```{r}
# visualize the factors after rotation

# convert samples of Lambda to a list
LambdaSamps <- lapply(seq(dim(post_samples_event$Lambda)[1]), function(x) post_samples_event$Lambda[x ,c(1,3,5,7,6,8,2,4,9,10), ])

# run the match align algorithm
vari = lapply(LambdaSamps, varimax)
loads = lapply(vari, `[[`, 1)
norms = sapply(loads, norm, "2")
pivot = loads[order(norms)][[1000]]
aligned = lapply(loads, msf, pivot)
aligned_mat <- summat(aligned)

# make df for plotting
factor <- rep(c("1","2","3", "4", "5"), each=10)
loading <- c(aligned_mat[,1], aligned_mat[,2], aligned_mat[,3], aligned_mat[,4], aligned_mat[,5])
random_effect <- rep(c("gamma_RA",
                       "alpha_RA",
                       "gamma_RN",
                       "alpha_RN",
                       "gamma_NR",
                       "alpha_NR",
                       "gamma_NA",
                       "alpha_NA",
                       "phi_R",
                       "phi_N"), 5)
plot_df <- data.frame(factor, loading, random_effect)
plot_df$random_effect <- factor(plot_df$random_effect, levels = c("gamma_RA",
                       "alpha_RA",
                       "gamma_RN",
                       "alpha_RN",
                       "gamma_NR",
                       "alpha_NR",
                       "gamma_NA",
                       "alpha_NA",
                       "phi_R",
                       "phi_N"))
ggplot(plot_df, aes(x=factor, y=random_effect, fill=loading)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue",
                       mid = "white",
                       high = "darkorange") +
  labs(title="Aligned factor loadings for random effects",
       subtitle="Loadings for which the 95% credible interval contains zero are set to zero",
       y="")

  
```

```{r}
# check mixing of the aligned factors
Lambda_11 <- rep(NA, 10000)
for (i in 1:10000) {
  Lambda_11[i] <- aligned[[i]][10,1]
}
plot(Lambda_11, type="l")
```


```{r}
# make vectors with the means and upper/lower 95% credible bounds for the rate parameters
rate_means <- c(mean(post_samples_event$lambda_R), mean(post_samples_event$lambda_N))
rate_lower <- c(quantile(post_samples_event$lambda_R, probs=c(0.025)), 
                quantile(post_samples_event$lambda_N, probs=c(0.025)))
rate_upper <- c(quantile(post_samples_event$lambda_R, probs=c(0.975)), 
                quantile(post_samples_event$lambda_N, probs=c(0.975)))
rate_names <- c("lambda_R", "lambda_N")


rate_main_df <- data.frame(rate_means, rate_lower, rate_upper, rate_names)
names(rate_main_df) <- c("posterior_mean", "lower", "upper", "parameter")


ggplot(data=rate_main_df, aes(x=parameter, y=posterior_mean)) +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  ylim(0, 0.025) +
  geom_point(color="red") +
  coord_flip() +
  labs(title="Inter-event time model fixed effects",
       x="", y="")

```


```{r}
# make vectors with the means and upper/lower 95% credible bounds for the rate parameters
rate_means <- c(mean(cov_mat_samples[9,9,]), mean(cov_mat_samples[10,10,]))
rate_lower <- c(quantile(cov_mat_samples[9,9,], probs=c(0.025)), 
                quantile(cov_mat_samples[10,10,], probs=c(0.025)))
rate_upper <- c(quantile(cov_mat_samples[9,9,], probs=c(0.975)), 
                quantile(cov_mat_samples[10,10,], probs=c(0.975)))
rate_names <- c("var(phi_R)", "var(phi_N)")


rate_re_var_df <- data.frame(rate_means, rate_lower, rate_upper, rate_names)
names(rate_re_var_df) <- c("posterior_mean", "lower", "upper", "parameter")


ggplot(data=rate_re_var_df, aes(x=parameter, y=posterior_mean)) +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  ylim(0, 0.9) +
  geom_point(color="red") +
  coord_flip() +
  labs(title="Inter-event time model random effect variances",
       x="", y="")

```

```{r}
# visualize main effects
maineffect_means <- apply(post_samples_event$mu_tau, c(2,3), mean)
maineffect_lower <- apply(post_samples_event$mu_tau, c(2,3), quantile, probs=0.025)
maineffect_upper <- apply(post_samples_event$mu_tau, c(2,3), quantile, probs=0.975)
maineffect_names <- t(matrix(c("mu_RA", "mu_RN",
                             "mu_NA", "mu_NR",
                             "tau_RA", "tau_RN",
                             "tau_NA", "tau_NR"),
                           nrow=2, ncol=4))

maineffect_means
maineffect_lower
maineffect_upper
maineffect_names

maineffect_df <- data.frame(as.vector(maineffect_names),
                            as.vector(maineffect_means),
                            as.vector(maineffect_lower),
                            as.vector(maineffect_upper))
names(maineffect_df) <- c("parameter", "posterior_mean", "lower", "upper")

# reorder names for plotting
maineffect_df$parameter <- factor(maineffect_df$parameter, levels=c("tau_RN", "tau_RA",
                                                                    "tau_NR", "tau_NA",
                                                                    "mu_RN", "mu_RA",
                                                                    "mu_NR", "mu_NA"))


ggplot(data=maineffect_df, aes(x=parameter, y=posterior_mean)) +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  geom_hline(yintercept = 0, color="black") +
  geom_point(color="red") +
  coord_flip() +
  labs(title="Markov transition model fixed effects",
       subtitle="mus are transition effects; taus are shifts by apnea event",
       x="", y="")

```


```{r}
# make vectors with the means and upper/lower 95% credible bounds for the rate parameters
var_order <- c(1,3,5,7,6,8,2,4,9,10)
#var_order <- 1:10

rate_means <- rep(NA, 8)
rate_lower <- rep(NA, 8)
rate_upper <- rep(NA, 8)
for (i in 1:8) {
  rate_means[i] <- mean(cov_mat_samples[var_order[i],var_order[i],])
  rate_lower[i] <- quantile(cov_mat_samples[var_order[i],var_order[i],], probs=c(0.025))
  rate_upper[i] <- quantile(cov_mat_samples[var_order[i],var_order[i],], probs=c(0.975))
}
rate_names <- colnames(corr_mat)[1:8]


rate_re_var_df <- data.frame(rate_means, rate_lower, rate_upper, rate_names)
names(rate_re_var_df) <- c("posterior_mean", "lower", "upper", "parameter")

rate_re_var_df$parameter <- factor(rate_re_var_df$parameter, levels=c("alpha_RN", "alpha_RA",
                                                                    "alpha_NR", "alpha_NA",
                                                                    "gamma_RN", "gamma_RA",
                                                                    "gamma_NR", "gamma_NA"))

# add var() for matching the event plot
rate_re_var_df <- rate_re_var_df |>
  mutate(parameter_label = case_when(
    parameter == "alpha_RN" ~ "var(alpha_RN)",
    parameter == "alpha_RA" ~ "var(alpha_RA)",
    parameter == "alpha_NR" ~ "var(alpha_NR)",
    parameter == "alpha_NA" ~ "var(alpha_NA)",
    parameter == "gamma_RN" ~ "var(gamma_RN)",
    parameter == "gamma_RA" ~ "var(gamma_RA)",
    parameter == "gamma_NR" ~ "var(gamma_NR)",
    parameter == "gamma_NA" ~ "var(gamma_NA)"
  ))

rate_re_var_df$parameter_label <- factor(rate_re_var_df$parameter_label, levels=c("var(alpha_RN)", "var(alpha_RA)",
                                                                    "var(alpha_NR)", "var(alpha_NA)",
                                                                    "var(gamma_RN)", "var(gamma_RA)",
                                                                    "var(gamma_NR)", "var(gamma_NA)"))

ggplot(data=rate_re_var_df, aes(x=parameter_label, y=posterior_mean)) +
  geom_errorbar(aes(ymin=lower, ymax=upper)) +
  ylim(0, 1) +
  geom_point(color="red") +
  coord_flip() +
  labs(title="Markov transition model random effect variances",
       subtitle="gammas are transition effects; alphas are shifts by apnea event",
       x="", y="")

```


## Clustering

```{r}
# load posterior samples to use for clustering (same as from model fit above)
joint_fit_factor <- readRDS("joint_fit_factor_k5_n1093_m2500_chain4.rds")

# extract posterior samples and visualize
post_samples_event <- extract(joint_fit_factor)
```


```{r}
# organize posterior samples of theta
m <- 10000
N <- 1093
theta_samples <- array(dim=c(10,N,m))
for (l in 1:m) {
  for (i in 1:N) {
    theta_samples[1:8,i,l] <- as.vector(post_samples_event$gamma_alpha[l,((i-1)*4 + 1):(i*4),1:2])
    theta_samples[9,i,l] <- post_samples_event$phi_R[l,i]
    theta_samples[10,i,l] <- post_samples_event$phi_N[l,i]
  }
}
```

```{r}
# compute posterior means of thetas
theta_postmean <- apply(theta_samples, c(2,1), mean)
```


```{r}
##### get cluster labels (Bayes optimal)

# run k-means using posterior means
k <- 4
km.out.bayes4 <- kmeans(theta_postmean, centers=k, nstart=50)
label_init <- km.out.bayes4$cluster
label_init
km.out.bayes4$size
```

```{r}
# compute UQ -- probability that an individual's theta_i is closest to center c_k
c1_probs <- rep(0, 1093)
c2_probs <- rep(0, 1093)
c3_probs <- rep(0, 1093)
c4_probs <- rep(0, 1093)

# centers
c1 <- km.out.bayes4$centers[1,]
c2 <- km.out.bayes4$centers[2,]
c3 <- km.out.bayes4$centers[3,]
c4 <- km.out.bayes4$centers[4,]


for (i in 1:N) {
  for (j in 1:m) {
    theta_curr <- theta_samples[,i,j]
    d1_curr <- sum((theta_curr - c1)^2)
    d2_curr <- sum((theta_curr - c2)^2)
    d3_curr <- sum((theta_curr - c3)^2)
    d4_curr <- sum((theta_curr - c4)^2)
    min_dist_index <- which.min(c(d1_curr,d2_curr,d3_curr,d4_curr))
    if (min_dist_index == 1) {
      c1_probs[i] <- c1_probs[i] + 1 / m
    }
    else if (min_dist_index == 2) {
      c2_probs[i] <- c2_probs[i] + 1 / m
    }
    else if (min_dist_index == 3) {
      c3_probs[i] <- c3_probs[i] + 1 / m
    }
    else if (min_dist_index == 4) {
      c4_probs[i] <- c4_probs[i] + 1 / m
    }
  }
}
```




